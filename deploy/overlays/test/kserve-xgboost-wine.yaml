apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: wine-xgboost
  namespace: default
  annotations:
    # for rawDeployment + HPA autoscaling
    serving.kserve.io/deploymentMode: "RawDeployment"
    serving.kserve.io/autoscalerClass: "hpa"
    serving.kserve.io/metrics: "cpu"
    serving.kserve.io/targetUtilizationPercentage: "75"
spec:
  predictor:
    minReplicas: 1
    maxReplicas: 5
    serviceAccountName: sa
    containerConcurrency: 5
    triton:
      storageUri: "s3://models"
      resources:
        requests:
          cpu: "100m"
          memory: "256Mi"
        limits:
          cpu: "500m"
          memory: "512Mi"
      env:
        - name: OMP_NUM_THREADS
          value: "1"
        - name: KMP_AFFINITY
          value: "granularity=fine,compact,1,0"
        - name: KMP_BLOCKTIME
          value: "1"
---
# Optional: convert the existing service to NodePort
apiVersion: v1
kind: Service
metadata:
  name: wine-xgboost-predictor-default
  namespace: default
spec:
  type: NodePort
  selector:
    serving.kserve.io/inferenceservice: wine_xgboost
  ports:
    - name: http-inference
      port: 8000
      targetPort: 8000
      nodePort: 30000
    - name: grpc-inference
      port: 8001
      targetPort: 8001
      nodePort: 30001
